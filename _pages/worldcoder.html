---
layout: project
permalink: /projects/worldcoder
title: "WorldCoder"
---

<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>WorldCoder, a Model-Based LLM Agent | Building World Models by Writing Code and Interacting with the
        Environment</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />

    <link rel="stylesheet" href="{{ base_path }}/assets/css/static/css/bulma.min.css" />
    <link rel="stylesheet" href="{{ base_path }}/assets/css/static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="{{ base_path }}/assets/css/static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="{{ base_path }}/assets/css/static/css/fontawesome.all.min.css" />
    <link rel="stylesheet" href="{{ base_path }}/assets/css/static/css/academicons.min.css" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
    <link rel="stylesheet" href="{{ base_path }}/assets/css/static/css/index.css" />
    <link rel="stylesheet" href="{{ base_path }}/assets/css/static/css/worldcoder.css" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="{{ base_path }}/assets/css/static/js/fontawesome.all.min.js"></script>
    <script src="{{ base_path }}/assets/css/static/js/bulma-carousel.min.js"></script>
    <script src="{{ base_path }}/assets/css/static/js/bulma-slider.min.js"></script>
    <script src="{{ base_path }}/assets/css/static/js/index.js"></script>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <!-- <link rel="stylesheet" href="/assets/css/static/css/bulma.min.css" />
    <link rel="stylesheet" href="/assets/css/static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="/assets/css/static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="/assets/css/static/css/fontawesome.all.min.css" />
    <link rel="stylesheet" href="/assets/css/static/css/academicons.min.css" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
    <link rel="stylesheet" href="/assets/css/static/css/index.css" />
    <link rel="stylesheet" href="/assets/css/static/css/worldcoder.css" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="/assets/css/static/js/fontawesome.all.min.js"></script>
    <script src="/assets/css/static/js/bulma-carousel.min.js"></script>
    <script src="/assets/css/static/js/bulma-slider.min.js"></script>
    <script src="/assets/css/static/js/index.js"></script> -->
</head>

<body>
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">WorldCoder, a Model-Based LLM Agent: Building World
                            Models by Writing Code and Interacting with the Environment</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a target="_blank" href="https://haotang1995.github.io/">Hao&#160;Tang</a>, <a
                                    target="_blank" href="https://darrenkey.github.io//">Darren&#160;Key,
                                    <a target="_blank" href="https://www.cs.cornell.edu/~ellisk/">Kevin&#160;Ellis</a>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block">Cornell University </span>
                        </div>


                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- TODO PDF Link. -->
                                <span class="link-block">
                                    <a target="_blank" href="https://arxiv.org/abs/2402.12275"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>

                                <span class="link-block">
                                    <a target="_blank" href="https://arxiv.org/pdf/2402.12275"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>PDF</span>
                                    </a>
                                </span>
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a target="_blank" href="https://github.com/haotang1995/WorldCoder"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                                <!--<span class="link-block">-->
                                <!--<a target="_blank" href="https://twitter.com/DrJimFan/status/1662115266933972993" class="external-link button is-normal is-rounded is-dark">-->
                                <!--<span class="icon">-->
                                <!--<i class="fab fa-twitter"></i>-->
                                <!--</span>-->
                                <!--<span>Tweet</span>-->
                                <!--</a>-->
                                <!--</span>-->
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p style="font-size: 125%;">
                            We give a model-based agent that builds a Python program representing its knowledge of the
                            world based on its interactions with the environment. The world model
                            tries to explain its interactions, while also being optimistic about what reward it
                            can achieve. We define this optimism as a logical constraint between a program
                            and a planner. We study our agent on gridworlds, and on task planning, finding our
                            approach is more sample-efficient compared to deep RL, more compute-efficient
                            compared to ReAct-style agents, and that it can transfer its knowledge across
                            environments by editing its code.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="rows">
                <div class="rows is-centered">
                    <div class="row is-full-width">
                        <div style="text-align: center;">
                            <img src="{{ base_url}}/files/worldcoder/framework.png" class="interpolation-image" alt=""
                                style="display: block; margin-left: auto; margin-right: auto; width: 80%;" />
                            <br />
                            <span style="font-size: 125%;">WorldCoder learns Python programs as the world models.</span>
                            <br />
                            <br />
                            <img src="{{ base_url}}/files/worldcoder/comparison.png" class="interpolation-image" alt=""
                                style="display: block; margin-left: auto; margin-right: auto; width: 80%;" />
                            <br />
                            <span style="font-size: 125%; width: 80%;"> Qualitative comparison of WorldCoder against
                                deep model-based RL and LLM agents. WorldCoder learns and adapts a symbolic world model
                                with much fewer interactions with the environments. </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!--Introduction-->
    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Introduction</span></h2>
                        <div class="content has-text-justified">
                            <span style="font-size: 125%;">
                                <p> Humans excel at quickly understanding new environments and unfamiliar tasks,
                                    leveraging prior knowledge and minimal experience to form actionable insights. Can
                                    AI achieve a similar level of adaptability and efficiency? Traditional neural-based
                                    methods often require extensive interactions to solve simple problems. WorldCoder
                                    addresses these challenges by integrating programmatic inductive biases with world
                                    model learning. Our agent adaptively learns a symbolic world model as code as shown
                                    in the above figure. Programmatic representations provide strong inductive biases,
                                    enabling WorldCoder to learn world models that are more sample-efficient,
                                    generalizable, and interpretable than neural-based methods. These models also excel
                                    in adaptability, transferability, and cost-effectiveness compared to traditional LLM
                                    agents. </p>
                            </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!--Method-->
    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">WorldCoder: Learning Python Code as World
                                Models</span></h2>
                        <div class="content has-text-justified">
                            <span style="font-size: 125%;">
                                WorldCoder builds on the classic model-based agent architecture, learning a world model
                                that predicts state transitions given current states and actions. The agent iterates
                                between:
                                <ul data-spread="false">
                                    <li> Acting based on the currently learned world model and storing the resulting
                                        experiences in the replay buffer. </li>
                                    <li> Updating the world model to align with past experiences. </li>
                                </ul>
                                <p> The process stops when the agent solves the problem or when further interactions
                                    become impossible.</p>
                                <p> WorldCoder represents the world model as Python code and leverages LLMs to
                                    synthesize these models. We develop a more efficient adaptive LLM-based code
                                    refinement method [<a style="color: #61afef;"
                                        href=" {{base_url}}/projects/rex">REX</a>] to synthesize the transition function
                                    s' = T(s, a) and the reward function r = R(s, a, s') that fully explain past
                                    interactions stored in the replay buffer. </p>
                            </span>
                        </div>

                        <h3 class="title is-4">Optimistic in the Face of Uncertainty </h3>
                        <div class="content has-text-justified">
                            <span style="font-size: 125%;">
                                <p> We further show that programmatic representations with LLM-guided program generation
                                    are compatible with a pervasive principle for efficient exploration: optimism under
                                    uncertainty. For instance, consider an agent that has learned to navigate but does
                                    not know how to open a door to reach its goal (the green square). Classic
                                    model-based agents might resort to random exploration, which is highly
                                    sample-inefficient, as shown in the blue trajectory in the figure. </p>
                                <img src="{{ base_url }}/files/worldcoder/optimistic.png" class="interpolation-image"
                                    alt="" style="display: block; margin-left: auto; margin-right: auto; width: 70%;" />
                                <p> In contrast, a more effective approach—much like human problem-solving—is to
                                    hypothesize and test potential solutions. For example, the agent might imagine that
                                    the key could unlock the door or that a specific mechanism might bypass it. Each
                                    hypothesis enables the agent to form a plan that is either correct (solving the
                                    problem) or incorrect (yielding a new informative counter-example to learn the
                                    correct world model of the environment). </p>
                                <p> This behavior exemplifies the principle of optimism under uncertainty. WorldCoder's
                                    synthesized world models not only align with past experiences but also generate
                                    actionable plans to achieve goals efficiently. </p>
                                <img src="{{ base_url }}/files/worldcoder/objective.png" class="interpolation-image"
                                    alt="" style="display: block; margin-left: auto; margin-right: auto; width: 60%;" />
                                <p> We also provide a theoretical analysis of the worst-case sample complexity required
                                    to solve a problem using this optimistic approach. For detailed proofs and
                                    demonstrations of WorldCoder’s human-like exploratory behavior, please refer to our
                                    paper (Appendix A).  </p>
                                <img src="{{ base_url }}/files/worldcoder/theorem.png" class="interpolation-image"
                                    alt="" style="display: block; margin-left: auto; margin-right: auto; width: 60%;" />
                            </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!--Experiments-->
    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Experiments</span></h2>
                        <div class="content has-text-justified">
                            <p style="font-size: 125%;">
                                We study our system in three environments, Sokoban, Minigid, and AlfWorld, with the goal
                                of understanding the sample efficiency and computational efficiency of the learner,
                                especially when transferring knowledge across environments, as well as the impact of
                                optimism under uncertainty. 
                            </p>
                        </div>
                        <p style="font-size: 125%;">

                            The findings highlight several advantages:
                            <br />
                            <br />
                            <img src="{{ base_url }}/files/worldcoder/soko-result.png" class="interpolation-image"
                                alt="" style="display: block; margin-left: auto; margin-right: auto; width: 80%;" />
                            <br />
                        <ul style="font-size: 125%;" data-spread="false">
                            <li> <strong>Generalization</strong>: WorldCoder's programmatic world models generalize
                                effectively to new scenarios, such as adapting from a 2-box Sokoban environment to a
                                3-box environment without additional training. </li>
                            <br>

                            <li> <strong>Sample-Efficiency</strong>: While neural-based methods require millions of
                                interactions, WorldCoder achieves comparable results with just hundreds. </li>
                            <br>
                            <li> <strong>Computational Efficiency</strong>: Classic LLM agents like ReAct rely on
                                frequent LLM queries. In contrast, WorldCoder front-loads LLM use, reducing overall
                                computational cost. </li>
                            <br>
                            How could an AI experiment with a new environment, and then very quickly learn how it works
                            and achieve a range of novel goals?<br><br>


                            Our agent <b> programs a world model in code;</b> explores by inventing reward functions it
                            optimistically thinks it can achieve; then <b>plans to achieve novel goals.</b>
                            On certain videogame and robot planning tasks, it learns <b>>10,000x faster than deep
                                RL,</b> at a
                            <b>fraction of the LLM cost of ReAct.</b>
                        </ul>
                        <br />
                        <h4 class="title is-4">World Model</h4>
                        <br>
                        <pre><code class="language-python">class Entity:
        def __init__(self, x, y):
            self.name = self.__class__.__name__
            self.x = x
            self.y = y
        def __repr__(self):
            return f'{self.name}({self.x}, {self.y})'
        def __eq__(self, other):
            return self.name == other.name and self.x == other.x and self.y == other.y
        def __hash__(self):
            return hash((self.name, self.x, self.y))
    class Player(Entity): pass
    class Wall(Entity): pass
    class Box(Entity): pass
    class Teleporter(Entity): pass
    class Target(Entity): pass
    def get_entities_by_name(entities, name):
        return [ entity for entity in entities if entity.name == name ]
    def get_entities_by_position(entities, x, y):
        return [ entity for entity in entities if entity.x == x and entity.y == y ]
    def move_entity(entity, dx, dy, state):
        entity.x += dx
        entity.y += dy
        if any(isinstance(e, Wall) for e in get_entities_by_position(state, entity.x, entity.y)):
            # can't move into a Wall
            entity.x -= dx
            entity.y -= dy
        elif dx != 0 and any(isinstance(e, Box) for e in get_entities_by_position(state, entity.x, entity.y)):
            # push the box
            box = next(e for e in get_entities_by_position(state, entity.x, entity.y) if isinstance(e, Box))
            push_box = move_entity(box, dx, 0, state) if dx !=0 else move_entity(box, 0, dy, state)
            if not push_box:
                # can't move the box into a Wall
                entity.x -= dx
                entity.y -= dy
        return True
    def can_move_to(entity, dx, dy, state):
        new_x, new_y = entity.x + dx, entity.y + dy
        entities_in_destination = get_entities_by_position(state, new_x, new_y)
        is_destination_blocked = any(isinstance(e, Wall) for e in entities_in_destination)
        would_box_be_pushed_off_grid = (new_x < 0 or new_y < 0 or new_x > 6 or new_y > 6)
        return not (is_destination_blocked or would_box_be_pushed_off_grid)
    def move_entity_if_possible(entity, dx, dy, state):
        if can_move_to(entity, dx, dy, state):
            entity.x += dx
            entity.y += dy
            # return True if successful
            return True
        # return False if unsuccesful
        return False
    def transition(state, action):
        player = get_entities_by_name(state, "Player")[0]
        dx, dy = 0, 0
        if action == "move up":
            dx, dy = 0, -1
        elif action == "move down":
            dx, dy = 0, 1
        elif action == "move left":
            dx, dy = -1, 0
        elif action == "move right":
            dx, dy = 1, 0
        if action.startswith('move'):
            entities_in_destination = get_entities_by_position(state, player.x + dx, player.y + dy)
            if any(isinstance(e, Box) for e in entities_in_destination):  # if there is a box in the destination
                box = next(e for e in entities_in_destination if isinstance(e, Box))
                entities_in_box_destination = get_entities_by_position(state, box.x + dx, box.y + dy)
                if not any(isinstance(e, Box) for e in entities_in_box_destination) and not any(isinstance(e, Wall) for e in entities_in_box_destination):  # Box cannot be pushed into another box or wall.
                    box_pushed = move_entity_if_possible(box, dx, dy, state)
                    if box_pushed:  # if box was successfully pushed, move player
                        move_entity_if_possible(player, dx, dy, state)
            else:  # if there is no box in the destination, move player
                move_entity_if_possible(player, dx, dy, state)
        elif action == "activate":
            activate_teleporter(player, state)
        return state
    def activate_teleporter(entity, state):
        current_position_entities = get_entities_by_position(state, entity.x, entity.y)
        if any(isinstance(e, Teleporter) for e in current_position_entities):
            # can only activate if on a Teleporter
            teleporters = get_entities_by_name(state, 'Teleporter')
            other_teleporter = next(t for t in teleporters if t.x != entity.x or t.y != entity.y)
            other_teleporter_x = other_teleporter.x
            other_teleporter_y = other_teleporter.y
            other_teleported_position_entities = get_entities_by_position(state, other_teleporter_x, other_teleporter_y)
            if any(isinstance(e, Box) for e in other_teleported_position_entities):  # if there is a box on the other teleporter
                box_on_teleporter = next(e for e in other_teleported_position_entities if isinstance(e, Box))
                push_x = box_on_teleporter.x - entity.x
                push_y = box_on_teleporter.y - entity.y
                # Check if the box can be moved in the pushed direction
                if can_move_to(box_on_teleporter, push_x, push_y, state):
                    move_entity(box_on_teleporter, push_x, push_y, state)  # push the box
                    entity.x = other_teleporter.x
                    entity.y = other_teleporter.y
                    return True
            else:
                entity.x = other_teleporter.x
                entity.y = other_teleporter.y
                return True
        return False</code></pre>
                        <br> <br>
                        <h4 class="title is-4">Reward Function</h4>
                        <br>
                        <pre><code>def reward_func(state, action, next_state):
        targets_state = get_entities_by_name(state, 'Target')
        boxes_state = get_entities_by_name(state, 'Box')
        targets_next_state = get_entities_by_name(next_state, 'Target')
        boxes_next_state = get_entities_by_name(next_state, 'Box')
        # Count the number of boxes placed on targets in the state and next_state.
        boxes_on_targets_state = sum([any(box.x == target.x and box.y == target.y for box in boxes_state) for target in targets_state])
        boxes_on_targets_next_state = sum([any(box.x == target.x and box.y == target.y for box in boxes_next_state) for target in targets_next_state])
        # Determine the reward based on an increase in count of boxes on targets
        if boxes_on_targets_next_state > boxes_on_targets_state:
            reward = 0.9  # box was moved onto a target
        else:
            reward = -0.1  # no box was moved onto a target
        # Determine if the game is finished
        done = all(any(box.x == target.x and box.y == target.y for box in boxes_next_state) for target in targets_next_state)    
        if done:
            reward += 10  # Adding 10 bonus for completing the game
        return reward, done</code></pre>

                        <center>
                            <video controls muted autoplay loop width="40%">
                                <source src="{{ base_url }}/files/worldcoder/tele-sokoban.webm" type="video/webm" />
                            </video>
                        </center>


                        <!-- <video controls="" muted="" autoplay="" loop="" width="40%">
                                <source src="{{ base_url }}/files/worldcoder/tele-sokoban.mp4" type="video/mp4">
                            </video> -->

                        <br />
                        <span style="font-size: 125%;">Additionally, in environments designed to be outside LLM
                            pretraining corpora, WorldCoder demonstrates its ability to learn novel dynamics,
                            such
                            as
                            using teleporters in Sokoban for more efficient problem-solving.</span>
                        <br />
                        <br />
                        <img src="{{ base_url }}/files/worldcoder/minigrid-result.png" class="interpolation-image"
                            alt="" style="display: block; margin-left: auto; margin-right: auto; width: 80%;" />
                        <br />
                        <ul style="font-size: 125%;" data-spread="false">
                            <li><strong>Adaptability and Transfer</strong>: WorldCoder excels in adapting and
                                transferring knowledge to new tasks. For example, solving the “unlock” task from
                                scratch
                                typically requires hundreds of interactions to learn navigation, key-picking,
                                and
                                door-opening. However, WorldCoder transfers knowledge from the “door-key”
                                environment,
                                enabling near-zero-shot generalization by simply synthesizing a new reward
                                function
                                given the new text goal.</li> <br>
                            <li><strong>Sample Efficient Exploration with the Optimistic Objective</strong>: The
                                optimistic objective significantly enhances sample-efficient exploration,
                                particularly
                                in challenging environments like Minigrid and AlfWorld. This approach allows the
                                agent
                                to discover effective strategies even in sparse-reward scenarios, where
                                exploration
                                is
                                typically more difficult.</li>
                        </ul>
                        <br />
                        <img src="{{ base_url }}/files/worldcoder/alfworld-result.png" class="interpolation-image"
                            alt="" style="display: block; margin-left: auto; margin-right: auto; width: 80%;" />
                        <br />
                        <ul style="font-size: 125%;" data-spread="false">
                            <li><strong>Interpretability</strong>: Programmatic world models offer exceptional
                                clarity
                                and auditability. By examining the generated code, one can directly see which
                                knowledge
                                has been acquired and how it is represented. This transparency also highlights
                                where
                                additional interactions with the environment are needed to expand the agent's
                                understanding.</li>
                        </ul>
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!--Conclusion-->
    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Conclusion</span></h2>
                        <div class="content has-text-justified">
                            <p style="font-size: 125%;">
                                WorldCoder represents a step forward in creating AI systems that learn efficiently,
                                adaptively, and transparently. It learns Python code to model the world and act
                                optimistically, enabling it to efficiently explore and adapt to its environment. While
                                challenges remain, the integration of LLMs with symbolic reasoning offers a promising
                                direction for building AI that interacts with the world as seamlessly as humans.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section" id="BibTeX">
        <div class="container is-max-widescreen content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@inproceedings{tang2024worldcoder,
  title={Worldcoder, a model-based llm agent: Building world models by writing code and interacting with the environment},
  author={Tang, Hao and Key, Darren and Ellis, Kevin},
  booktitle = {Advances in Neural Information Processing Systems},
  year={2024}
}</code></pre>
        </div>
    </section>

    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column">
                    <div class="content has-text-centered">
                        <p>
                            Website template borrowed from <a href="https://voyager.minedojo.org/"
                                target="_blank">Voyager</a>, <a href="https://github.com/nerfies/nerfies.github.io"
                                target="_blank">NeRFies</a>, <a href="https://github.com/cliport/cliport.github.io"
                                target="_blank">CLIPort</a>, and
                            <a href="https://github.com/vimalabs/vimalabs.github.io" target="_blank">VIMA</a>.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>
</body>

</html>